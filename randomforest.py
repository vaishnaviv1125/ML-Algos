# -*- coding: utf-8 -*-
"""randomforest.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FTrAq9gBBZ_Ge36mcMVnHewdwmCvQLL0
"""

#WINE QUALITY PREDICTION

#IMPORTING THE LIBRARIES

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

#IMPORT THE DATASET

wine_dataset=pd.read_csv('/content/winequality-red.csv')

#TO KNOW THE NUMBER OF ROWS AND COLUMNS
wine_dataset.shape

#DISPLAYS THE 1ST 5 ROWS OF THE DATASET
wine_dataset.head()

#TO CHECK THE MISSING VALUES
wine_dataset.isnull().sum()

#INFORMATION ABOUT THE DATASET

wine_dataset.info()

#STATISTICAL MEASURES OF THE DATASET

wine_dataset.describe()

#This plots a count plot (like a bar chart) showing how many wines fall into each quality level.
sns.catplot(x="quality", data=wine_dataset, kind="count")

# volatile acidity vs quality
plot = plt.figure(figsize = (5,5))
sns.barplot(x = "quality", y = "volatile acidity", data = wine_dataset)
plt.show()

# citric acid vs quality
plot = plt.figure(figsize = (5,5))
sns.barplot(x = "quality", y = "citric acid", data = wine_dataset)
plt.show()

# correlation
#This computes the correlation matrix between all numeric features in your wine_dataset
correlation = wine_dataset.corr()
print(correlation)

# heatmap for correlation
plt.figure(figsize = (10,10))
sns.heatmap(correlation, cbar = True, square = True, fmt = '.1f', annot = True, annot_kws = {"size": 8})
plt.show()

# It separates the features (X) from the label (y).
X = wine_dataset.drop("quality", axis = 1)

#label binarization or label encoding
#Converting a multi-class quality label into a binary classification problem:
#If quality >= 7 → 1 (Good Quality)
#Else → 0 (Bad or Average Quality)
Y = wine_dataset["quality"].apply(lambda y_value: 1 if y_value >= 7 else 0)

print(X)
print(Y)

"""X contains the features of the wine dataset after removing the "quality" column.
Y contains the target labels derived from the "quality" column, where wines with a quality score of 7 or higher are labeled as 1, and wines with a quality score below 7 are labeled as 0.
"""

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, stratify = Y, random_state = 2)

"""X_train, X_test: These variables store the features of the training and testing sets, respectively.

Y_train, Y_test: These variables store the target labels of the training and testing sets, respectively. train_test_split(): This function is used to split the dataset into random train and test subsets.

X: This is the feature dataset.

Y: This is the target label dataset.

test_size: It specifies the proportion of the dataset to include in the testing split.

stratify: It ensures that the splitting process maintains the same proportion of target classes as in the original dataset.

random_state: It sets the random seed for reproducibility.
"""

print("Total data: ", X.shape)
print("Train data: ", X_train.shape)
print("Test data: ", X_test.shape)

print(X_train) #prints the training featues dataset
print(Y_train) #prints the target labels

#MODEL TRAINING

model=RandomForestClassifier()
model.fit(X_train,Y_train)

#MODEL EVALUATION

#ACCURACY SCORE ON THE TRAINING DATA
X_train_prediciton = model.predict(X_train)
training_data_accuracy = accuracy_score(X_train_prediciton, Y_train)
print("Accuracy on training data: ", training_data_accuracy)

#ACCURACY SCORE ON THE TEST DATA

X_test_prediciton = model.predict(X_test)
test_data_accuracy = accuracy_score(X_test_prediciton, Y_test)
print("Accuracy on test data: ", test_data_accuracy)

Y_test.iloc[311]

"""Y_test: This variable represents the target labels of the test dataset.
.iloc[311]: This is an indexing method used to access the value at the specified integer location, in this case, the 311th row of the Y_test DataFrame.
"""

X_test.iloc[311]

"""X_test: This variable represents the features of the test dataset.
.iloc[311]: This is an indexing method used to access the data at the specified integer location, in this case, the 311th row of the X_test DataFrame.
"""

sample = X_test.iloc[311].values

print(sample)

input_data = (sample)

# changing the input data to numpy array
input_data_as_numpy_array = np.asarray(input_data)

# reshape data
input_data_reshaped = input_data_as_numpy_array.reshape(1, -1)

prediction = model.predict(input_data_reshaped)
print(prediction)

"""input_data: This variable holds the feature values of the data point for which prediction is to be made.

input_data_as_numpy_array: Converts the input data into a NumPy array, which is a common format for data manipulation in Python.

input_data_reshaped: Reshapes the input data array into a format that can be accepted by the model for prediction. The reshape method is used to reshape the array into a 2D array with one row and as many columns as there are features in the dataset. The -1 argument is used to infer the number of columns based on the length of the original array.

prediction: Uses the trained model (model) to predict the target variable for the input data. The predict method is applied to the reshaped input data to obtain the prediction.
"""

if(prediction[0] == 0):
    print("Poor Quality Wine.")
else:
    print("Good Quality Wine.")

!pip install gradio

import gradio as gr # Import the gradio library and alias it as 'gr'

def predict_wine_quality(fixed_acidity, volatile_acidity, citric_acid, residual_sugar, chlorides, free_sulfur_dioxide, total_sulfur_dioxide, density, pH, sulphates, alcohol):
    try:
        # Convert inputs to appropriate numeric format
        features = np.array([
            float(fixed_acidity),
            float(volatile_acidity),
            float(citric_acid),
            float(residual_sugar),
            float(chlorides),
            float(free_sulfur_dioxide),
            float(total_sulfur_dioxide),
            float(density),
            float(pH),
            float(sulphates),
            float(alcohol)
        ]).reshape(1, -1)

        # Make prediction using the trained model
        prediction = model.predict(features)

        # Return result based on prediction
        if prediction[0] == 0:
            return "Poor Quality Wine."
        else:
            return "Good Quality Wine."
    except Exception as e:
        return str(e)

# Define Gradio interface
demo = gr.Interface(
    fn=predict_wine_quality,
    inputs=[
        gr.Number(label="Fixed Acidity", value=7.4),
        gr.Number(label="Volatile Acidity", value=0.7),
        gr.Number(label="Citric Acid", value=0.0),
        gr.Number(label="Residual Sugar", value=1.9),
        gr.Number(label="Chlorides", value=0.076),
        gr.Number(label="Free Sulfur Dioxide", value=11.0),
        gr.Number(label="Total Sulfur Dioxide", value=34.0),
        gr.Number(label="Density", value=0.9978),
        gr.Number(label="pH", value=3.51),
        gr.Number(label="Sulphates", value=0.56),
        gr.Number(label="Alcohol", value=9.4)
    ],
    outputs="text",
    title="Wine Quality Prediction",
    description="Enter the features of the wine to predict its quality. The prediction will indicate whether the wine is of Good Quality or Poor Quality."
)

# Launch the Gradio app
demo.launch()

